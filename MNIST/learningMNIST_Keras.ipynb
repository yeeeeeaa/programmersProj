{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZVu3GwN3_kq"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the batch size\n",
        "batch_size = 20\n",
        "\n",
        "# Define a function for data preprocessing\n",
        "def preprocess_image(image, label):\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess and create TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.map(preprocess_image)\n",
        "train_dataset = train_dataset.shuffle(buffer_size=60000).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.map(preprocess_image)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "# Create data iterators for training and testing\n",
        "#train_data = iter(train_dataset)\n",
        "#test_data = iter(test_dataset)\n"
      ],
      "metadata": {
        "id": "1rhDdX2w4ZoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten the input\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "6kXwx766RMlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the NN architecture\n",
        "class Net(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten(input_shape=(28,28))\n",
        "        self.fc1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.fc3 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.fc4 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.fc5 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model = Net()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2AAuU20eBIG",
        "outputId": "47cec86e-d41b-45fa-ca30-a52d865fd8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Net object at 0x7dc9c3f93c10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()  # Changed optimizer to Adam\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "BNIwFLXBRQ7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs to train the model\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for data, target in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(data, training=True)\n",
        "            loss = loss_fn(target, output)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        train_loss += loss.numpy()\n",
        "\n",
        "    train_loss = train_loss / len(train_dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch + 1, train_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh0uu1WqzZe3",
        "outputId": "f926bb6a-e91b-4593-87aa-64eb1cb99d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.651917\n",
            "Epoch: 2 \tTraining Loss: 0.328588\n",
            "Epoch: 3 \tTraining Loss: 0.279013\n",
            "Epoch: 4 \tTraining Loss: 0.239703\n",
            "Epoch: 5 \tTraining Loss: 0.228043\n",
            "Epoch: 6 \tTraining Loss: 0.204213\n",
            "Epoch: 7 \tTraining Loss: 0.193412\n",
            "Epoch: 8 \tTraining Loss: 0.188731\n",
            "Epoch: 9 \tTraining Loss: 0.178332\n",
            "Epoch: 10 \tTraining Loss: 0.170848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "\n",
        "for data, target in test_dataset:\n",
        "    output = model(data, training=False)\n",
        "    loss = loss_fn(target, output)\n",
        "    test_loss += loss.numpy()\n",
        "\n",
        "    pred = tf.argmax(output, axis=1)\n",
        "    target = tf.cast(target, tf.int64)\n",
        "    correct = np.squeeze(pred == target)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        label = target[i].numpy()\n",
        "        class_correct[label] += correct[i]\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss / len(test_dataset)\n",
        "\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-cqrg2IvROt",
        "outputId": "781e1fa9-eb5a-468f-8a58-ab939106f678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.112703\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])\n",
        "        ))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (str(i)))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100 * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehnyUW0Hgtr1",
        "outputId": "0beb5977-8600-4f29-e3b6-03de1d28c617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of     0: 99% (973/980)\n",
            "Test Accuracy of     1: 98% (1123/1135)\n",
            "Test Accuracy of     2: 97% (1008/1032)\n",
            "Test Accuracy of     3: 96% (977/1010)\n",
            "Test Accuracy of     4: 97% (962/982)\n",
            "Test Accuracy of     5: 97% (872/892)\n",
            "Test Accuracy of     6: 97% (932/958)\n",
            "Test Accuracy of     7: 97% (1005/1028)\n",
            "Test Accuracy of     8: 94% (924/974)\n",
            "Test Accuracy of     9: 95% (964/1009)\n",
            "\n",
            "Test Accuracy (Overall): 97% (9740/10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the NN architecture\n",
        "class Net(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten(input_shape=(28,28))\n",
        "        self.fc1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(256, activation='relu')\n",
        "        self.fc3 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.fc4 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.fc5 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(self.bn1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(self.bn2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(self.bn3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model = Net()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ome9RRlP_MB",
        "outputId": "4fa11d01-0e23-42a5-e4bc-c16f3d4c8eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Net object at 0x7dc9c3f92ef0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()  # Changed optimizer to Adam\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KJt5QO_sQ8Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of epochs to train the model\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for data, target in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = model(data, training=True)\n",
        "            loss = loss_fn(target, output)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        train_loss += loss.numpy()\n",
        "\n",
        "    train_loss = train_loss / len(train_dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch + 1, train_loss))\n"
      ],
      "metadata": {
        "id": "es58azRCT4ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcab8537-51dd-484f-92a2-4fce0f2f13ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.958155\n",
            "Epoch: 2 \tTraining Loss: 0.557449\n",
            "Epoch: 3 \tTraining Loss: 0.474393\n",
            "Epoch: 4 \tTraining Loss: 0.424521\n",
            "Epoch: 5 \tTraining Loss: 0.398124\n",
            "Epoch: 6 \tTraining Loss: 0.379559\n",
            "Epoch: 7 \tTraining Loss: 0.364446\n",
            "Epoch: 8 \tTraining Loss: 0.346973\n",
            "Epoch: 9 \tTraining Loss: 0.343348\n",
            "Epoch: 10 \tTraining Loss: 0.338310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = [0] * 10\n",
        "class_total = [0] * 10\n",
        "\n",
        "for data, target in test_dataset:\n",
        "    output = model(data, training=False)\n",
        "    loss = loss_fn(target, output)\n",
        "    test_loss += loss.numpy()\n",
        "\n",
        "    pred = tf.argmax(output, axis=1)\n",
        "    target = tf.cast(target, tf.int64)\n",
        "    correct = np.squeeze(pred == target)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        label = target[i].numpy()\n",
        "        class_correct[label] += correct[i]\n",
        "        class_total[label] += 1\n",
        "\n",
        "test_loss = test_loss / len(test_dataset)\n",
        "\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMtjdbDFrMP",
        "outputId": "d1633aff-fd47-459e-84ee-c84c1f19c1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.207289\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])\n",
        "        ))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (str(i)))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100 * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnkDH2ZgFsjm",
        "outputId": "d7c8a204-37b3-487b-ea0d-0e874022af86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of     0: 98% (967/980)\n",
            "Test Accuracy of     1: 98% (1123/1135)\n",
            "Test Accuracy of     2: 96% (996/1032)\n",
            "Test Accuracy of     3: 96% (974/1010)\n",
            "Test Accuracy of     4: 96% (949/982)\n",
            "Test Accuracy of     5: 96% (858/892)\n",
            "Test Accuracy of     6: 96% (923/958)\n",
            "Test Accuracy of     7: 96% (988/1028)\n",
            "Test Accuracy of     8: 93% (914/974)\n",
            "Test Accuracy of     9: 94% (956/1009)\n",
            "\n",
            "Test Accuracy (Overall): 96% (9648/10000)\n"
          ]
        }
      ]
    }
  ]
}